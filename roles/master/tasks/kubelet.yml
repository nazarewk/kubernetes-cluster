- import_role: name=kubelet

- copy:
    dest: /etc/kubernetes/manifests/kube-apiserver.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: quay.io/coreos/hyperkube:{{ K8S_VER }}
          command:
          - /hyperkube
          - apiserver
          - --bind-address=0.0.0.0
          - --etcd-servers={{ ETCD_ENDPOINTS }}
          - --allow-privileged=true
          - --service-cluster-ip-range={{ SERVICE_IP_RANGE }}
          - --secure-port=443
          - --advertise-address={{ ADVERTISE_IP }}
          - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota
          - --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --service-account-key-file=/etc/kubernetes/ssl/apiserver-key.pem
          - --runtime-config=extensions/v1beta1/networkpolicies=true
          - --anonymous-auth=false
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              port: 8080
              path: /healthz
            initialDelaySeconds: 15
            timeoutSeconds: 15
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

- copy:
    dest: /etc/kubernetes/manifests/calico.yaml
    content: |
      # This ConfigMap is used to configure a self-hosted Calico installation.
      kind: ConfigMap
      apiVersion: v1
      metadata:
        name: calico-config
        namespace: kube-system
      data:
        # Configure this with the location of your etcd cluster.
        etcd_endpoints: "{{ ETCD_ENDPOINTS }}"

        # The CNI network configuration to install on each node.  The special
        # values in this config will be automatically populated.
        cni_network_config: |-
          {
              "name": "calico",
              "type": "flannel",
              "delegate": {
                "type": "calico",
                "etcd_endpoints": "__ETCD_ENDPOINTS__",
                "log_level": "info",
                "policy": {
                    "type": "k8s",
                    "k8s_api_root": "https://__KUBERNETES_SERVICE_HOST__:__KUBERNETES_SERVICE_PORT__",
                    "k8s_auth_token": "__SERVICEACCOUNT_TOKEN__"
                },
                "kubernetes": {
                    "kubeconfig": "/etc/kubernetes/cni/net.d/__KUBECONFIG_FILENAME__"
                }
              }
          }

      ---

      # This manifest installs the calico/node container, as well
      # as the Calico CNI plugins and network config on
      # each master and worker node in a Kubernetes cluster.
      kind: DaemonSet
      apiVersion: extensions/v1beta1
      metadata:
        name: calico-node
        namespace: kube-system
        labels:
          k8s-app: calico-node
      spec:
        selector:
          matchLabels:
            k8s-app: calico-node
        template:
          metadata:
            labels:
              k8s-app: calico-node
            annotations:
              scheduler.alpha.kubernetes.io/critical-pod: ''
              scheduler.alpha.kubernetes.io/tolerations: |
                [{"key": "dedicated", "value": "master", "effect": "NoSchedule" },
                 {"key":"CriticalAddonsOnly", "operator":"Exists"}]
          spec:
            hostNetwork: true
            containers:
              # Runs calico/node container on each Kubernetes node.  This
              # container programs network policy and routes on each
              # host.
              - name: calico-node
                image: quay.io/calico/node:v0.23.0
                env:
                  # The location of the Calico etcd cluster.
                  - name: ETCD_ENDPOINTS
                    valueFrom:
                      configMapKeyRef:
                        name: calico-config
                        key: etcd_endpoints
                  # Choose the backend to use.
                  - name: CALICO_NETWORKING_BACKEND
                    value: "none"
                  # Disable file logging so `kubectl logs` works.
                  - name: CALICO_DISABLE_FILE_LOGGING
                    value: "true"
                  - name: NO_DEFAULT_POOLS
                    value: "true"
                securityContext:
                  privileged: true
                volumeMounts:
                  - mountPath: /lib/modules
                    name: lib-modules
                    readOnly: false
                  - mountPath: /var/run/calico
                    name: var-run-calico
                    readOnly: false
                  - mountPath: /etc/resolv.conf
                    name: dns
                    readOnly: true
              # This container installs the Calico CNI binaries
              # and CNI network config file on each node.
              - name: install-cni
                image: quay.io/calico/cni:v1.5.2
                imagePullPolicy: Always
                command: ["/install-cni.sh"]
                env:
                  # CNI configuration filename
                  - name: CNI_CONF_NAME
                    value: "10-calico.conf"
                  # The location of the Calico etcd cluster.
                  - name: ETCD_ENDPOINTS
                    valueFrom:
                      configMapKeyRef:
                        name: calico-config
                        key: etcd_endpoints
                  # The CNI network config to install on each node.
                  - name: CNI_NETWORK_CONFIG
                    valueFrom:
                      configMapKeyRef:
                        name: calico-config
                        key: cni_network_config
                volumeMounts:
                  - mountPath: /host/opt/cni/bin
                    name: cni-bin-dir
                  - mountPath: /host/etc/cni/net.d
                    name: cni-net-dir
            volumes:
              # Used by calico/node.
              - name: lib-modules
                hostPath:
                  path: /lib/modules
              - name: var-run-calico
                hostPath:
                  path: /var/run/calico
              # Used to install CNI.
              - name: cni-bin-dir
                hostPath:
                  path: /opt/cni/bin
              - name: cni-net-dir
                hostPath:
                  path: /etc/kubernetes/cni/net.d
              - name: dns
                hostPath:
                  path: /etc/resolv.conf

      ---

      # This manifest deploys the Calico policy controller on Kubernetes.
      # See https://github.com/projectcalico/k8s-policy
      apiVersion: extensions/v1beta1
      kind: ReplicaSet
      metadata:
        name: calico-policy-controller
        namespace: kube-system
        labels:
          k8s-app: calico-policy
      spec:
        # The policy controller can only have a single active instance.
        replicas: 1
        template:
          metadata:
            name: calico-policy-controller
            namespace: kube-system
            labels:
              k8s-app: calico-policy
            annotations:
              scheduler.alpha.kubernetes.io/critical-pod: ''
              scheduler.alpha.kubernetes.io/tolerations: |
                [{"key": "dedicated", "value": "master", "effect": "NoSchedule" },
                 {"key":"CriticalAddonsOnly", "operator":"Exists"}]
          spec:
            # The policy controller must run in the host network namespace so that
            # it isn't governed by policy that would prevent it from working.
            hostNetwork: true
            containers:
              - name: calico-policy-controller
                image: calico/kube-policy-controller:v0.4.0
                env:
                  # The location of the Calico etcd cluster.
                  - name: ETCD_ENDPOINTS
                    valueFrom:
                      configMapKeyRef:
                        name: calico-config
                        key: etcd_endpoints
                  # The location of the Kubernetes API.  Use the default Kubernetes
                  # service for API access.
                  - name: K8S_API
                    value: "https://kubernetes.default:443"
                  # Since we're running in the host namespace and might not have KubeDNS
                  # access, configure the container's /etc/hosts to resolve
                  # kubernetes.default to the correct service clusterIP.
                  - name: CONFIGURE_ETC_HOSTS
                    value: "true"